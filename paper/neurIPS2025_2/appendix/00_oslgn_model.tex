\label{appendix:model-code}

The following PyTorch code defines the core components of the Operand Selective Logic Gated Neural Network (OSLGN) model.  
Operand selection uses binary masking via $\arg\max$ with a straight-through estimator (STE), and the operator module composes logic gates among 16 predefined binary functions.  
All logic outputs are strictly binary-valued and verified via runtime assertions.


The logic operator routing and the definition of 16 binary logic gates used in the \texttt{Operator} module are adapted from Petersen et al.~\cite{petersen2022deep}.  
Their original implementation is available at \url{https://github.com/Felix-Petersen/difflogic}.  
Unlike their soft-selection approach, we apply a straight-through estimator (STE) to enforce discrete operator selection during training, enabling train-time quantization within the logic gate routing mechanism.

\subsection{Operand Selector and Logic Operators}

\begin{lstlisting}[language=Python, caption={Operand selection and logic gate definitions.}]
class Operand_selector(nn.Module):
    def __init__(self, x, y):
        super().__init__()
        self.p = nn.Linear(x, y, bias=False)

    def forward(self, x):
        w = self.p.weight
        mask = torch.zeros_like(w).scatter_(1, w.argmax(dim=-1, keepdim=True), 1.0)
        masked = mask - w.detach() + w
        return F.linear(x, masked)
\end{lstlisting}

\subsection{Operator and Logic Layer Composition}
\begin{lstlisting}[language=Python, caption={Operator routing and composition of logic layers.}]
def bin_op(a, b, i):
    if i == 0: return torch.zeros_like(a)
    elif i == 1: return a * b
    elif i == 2: return a - a * b
    elif i == 3: return a
    elif i == 4: return b - a * b
    elif i == 5: return b
    elif i == 6: return a + b - 2 * a * b
    elif i == 7: return a + b - a * b
    elif i == 8: return 1 - (a + b - a * b)
    elif i == 9: return 1 - (a + b - 2 * a * b)
    elif i == 10: return 1 - b
    elif i == 11: return 1 - b + a * b
    elif i == 12: return 1 - a
    elif i == 13: return 1 - a + a * b
    elif i == 14: return 1 - a * b
    elif i == 15: return torch.ones_like(a)


class RoundSTE(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input):
        return torch.round(input)
    @staticmethod
    def backward(ctx, grad_output):
        return grad_output

def bin_op_s(a, b, i_s):
    r = torch.zeros_like(a)
    for i in range(16):
        r += i_s[..., i] * bin_op(a, b, i)
    return RoundSTE.apply(r)

class Operator(nn.Module):
    def __init__(self, y):
        super().__init__()
        self.weights = nn.Parameter(torch.randn(y, 16))

    def forward(self, a, b):
        w = self.weights
        mask = torch.zeros_like(w).scatter_(1, w.argmax(dim=-1, keepdim=True), 1.0)
        masked = mask - w.detach() + w
        return bin_op_s(a, b, masked)

class oslgn(nn.Module):
    def __init__(self, x, y):
        super().__init__()
        self.os1 = Operand_selector(x, y)
        self.os2 = Operand_selector(x, y)
        self.op = Operator(y)

    def forward(self, x):
        a = self.os1(x)
        b = self.os2(x)
        return self.op(a, b)
\end{lstlisting}
